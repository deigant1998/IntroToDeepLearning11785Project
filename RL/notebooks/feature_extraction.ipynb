{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict, namedtuple\n",
    "from io import open\n",
    "import math\n",
    "import os\n",
    "from random import shuffle, uniform\n",
    "from datetime import datetime\n",
    "from future.utils import iterkeys, iteritems\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from future.builtins import range\n",
    "from future.utils import iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    This method loads and returns the data in filename. If the data is labelled training data, it returns labels too.\n",
    "\n",
    "    Parameters:\n",
    "        filename: the location of the training or test data you want to load.\n",
    "\n",
    "    Returns:\n",
    "        data: a list of InstanceData objects from that data type and track.\n",
    "        labels (optional): if you specified training data, a dict of instance_id:label pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    # 'data' stores a list of 'InstanceData's as values.\n",
    "    data = []\n",
    "\n",
    "    # If this is training data, then 'labels' is a dict that contains instance_ids as keys and labels as values.\n",
    "    training = False\n",
    "    if filename.find('train') != -1:\n",
    "        training = True\n",
    "\n",
    "    if training:\n",
    "        labels = []\n",
    "\n",
    "    num_exercises = 0\n",
    "    print('Loading instances...')\n",
    "    instance_properties = dict()\n",
    "\n",
    "    with open(filename, 'rt') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "            if len(line) == 0:\n",
    "                num_exercises += 1\n",
    "                if num_exercises % 100000 == 0:\n",
    "                    print('Loaded ' + str(len(data)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
    "                instance_properties = dict()\n",
    "\n",
    "            # If the line starts with #, then we're beginning a new exercise\n",
    "            elif line[0] == '#':\n",
    "                if 'prompt' in line:\n",
    "                    instance_properties['prompt'] = line.split(':')[1]\n",
    "                else:\n",
    "                    list_of_exercise_parameters = line[2:].split()\n",
    "                    for exercise_parameter in list_of_exercise_parameters:\n",
    "                        [key, value] = exercise_parameter.split(':')\n",
    "                        if key == 'countries':\n",
    "                            value = value.split('|')\n",
    "                        elif key == 'days':\n",
    "                            value = float(value)\n",
    "                        elif key == 'time':\n",
    "                            if value == 'null':\n",
    "                                value = None\n",
    "                            else:\n",
    "                                assert '.' not in value\n",
    "                                value = int(value)\n",
    "                        instance_properties[key] = value\n",
    "\n",
    "            # Otherwise we're parsing a new Instance for the current exercise\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if training:\n",
    "                    assert len(line) == 7\n",
    "                else:\n",
    "                    assert len(line) == 6\n",
    "                assert len(line[0]) == 12\n",
    "\n",
    "                instance_properties['instance_id'] = line[0]\n",
    "\n",
    "                instance_properties['token'] = line[1]\n",
    "                instance_properties['part_of_speech'] = line[2]\n",
    "\n",
    "                instance_properties['morphological_features'] = dict()\n",
    "                for l in line[3].split('|'):\n",
    "                    [key, value] = l.split('=')\n",
    "                    if key == 'Person':\n",
    "                        value = int(value)\n",
    "                    instance_properties['morphological_features'][key] = value\n",
    "\n",
    "                instance_properties['dependency_label'] = line[4]\n",
    "                instance_properties['dependency_edge_head'] = int(line[5])\n",
    "                if training:\n",
    "                    label = float(line[6])\n",
    "                    labels.append(label)\n",
    "                data.append(InstanceData(instance_properties=instance_properties))\n",
    "\n",
    "        print('Done loading ' + str(len(data)) + ' instances across ' + str(num_exercises) +\n",
    "              ' exercises.\\n')\n",
    "\n",
    "    if training:\n",
    "        return data, labels\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceData(object):\n",
    "    \"\"\"\n",
    "    A bare-bones class to store the included properties of each instance. This is meant to act as easy access to the\n",
    "    data, and provides a launching point for deriving your own features from the data.\n",
    "    \"\"\"\n",
    "    def __init__(self, instance_properties):\n",
    "\n",
    "        # Parameters specific to this instance\n",
    "        self.instance_id = instance_properties['instance_id']\n",
    "        self.token = instance_properties['token']\n",
    "        self.part_of_speech = instance_properties['part_of_speech']\n",
    "        self.morphological_features = instance_properties['morphological_features']\n",
    "        self.dependency_label = instance_properties['dependency_label']\n",
    "        self.dependency_edge_head = instance_properties['dependency_edge_head']\n",
    "\n",
    "        # Derived parameters specific to this instance\n",
    "        self.exercise_index = int(self.instance_id[8:10])\n",
    "        self.token_index = int(self.instance_id[10:12])\n",
    "\n",
    "        # Derived parameters specific to this exercise\n",
    "        self.exercise_id = self.instance_id[:10]\n",
    "\n",
    "        # Parameters shared across the whole session\n",
    "        self.user = instance_properties['user']\n",
    "        self.countries = instance_properties['countries']\n",
    "        self.days = instance_properties['days']\n",
    "        self.client = instance_properties['client']\n",
    "        self.session = instance_properties['session']\n",
    "        self.format = instance_properties['format']\n",
    "        self.time = instance_properties['time']\n",
    "        self.prompt = instance_properties.get('prompt', None)\n",
    "\n",
    "        # Derived parameters shared across the whole session\n",
    "        self.session_id = self.instance_id[:8]\n",
    "\n",
    "    def to_features(self):\n",
    "        \"\"\"\n",
    "        Prepares those features that we wish to use in the LogisticRegression example in this file. We introduce a bias,\n",
    "        and take a few included features to use. Note that this dict restructures the corresponding features of the\n",
    "        input dictionary, 'instance_properties'.\n",
    "\n",
    "        Returns:\n",
    "            to_return: a representation of the features we'll use for logistic regression in a dict. A key/feature is a\n",
    "                key/value pair of the original 'instance_properties' dict, and we encode this feature as 1.0 for 'hot'.\n",
    "        \"\"\"\n",
    "        to_return = dict()\n",
    "\n",
    "        to_return['bias'] = 1.0\n",
    "        to_return['user:' + self.user] = 1.0\n",
    "        to_return['format:' + self.format] = 1.0\n",
    "        to_return['token:' + self.token.lower()] = 1.0\n",
    "\n",
    "        to_return['part_of_speech:' + self.part_of_speech] = 1.0\n",
    "        for morphological_feature in self.morphological_features:\n",
    "            to_return['morphological_feature:' + morphological_feature] = 1.0\n",
    "        to_return['dependency_label:' + self.dependency_label] = 1.0\n",
    "        \n",
    "        time = datetime.now()\n",
    "        if(time.second %10 == 0 and time.microsecond == 0):\n",
    "          print(time)\n",
    "          \n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(filename):\n",
    "    \"\"\"\n",
    "    This loads labels, either the actual ones or your predictions.\n",
    "\n",
    "    Parameters:\n",
    "        filename: the filename pointing to your labels\n",
    "\n",
    "    Returns:\n",
    "        labels: a dict of instance_ids as keys and labels between 0 and 1 as values\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "\n",
    "    with open(filename, 'rt') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                line = line.split()\n",
    "            instance_id = line[0]\n",
    "            label = float(line[1])\n",
    "            labels.append(label)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading instances...\n",
      "Loaded 317049 instances across 100000 exercises...\n",
      "Loaded 635368 instances across 200000 exercises...\n",
      "Loaded 951536 instances across 300000 exercises...\n",
      "Loaded 1271940 instances across 400000 exercises...\n",
      "Loaded 1591344 instances across 500000 exercises...\n",
      "Loaded 1911212 instances across 600000 exercises...\n",
      "Loaded 2227444 instances across 700000 exercises...\n",
      "Loaded 2546704 instances across 800000 exercises...\n",
      "Done loading 2622957 instances across 824012 exercises.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data, training_labels = load_data(\"en_es/en_es.slam.20190204.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(training_data[4].token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2622957/2622957 [02:42<00:00, 16161.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for data_point in tqdm(training_data):\n",
    "    data_feats = data_point.to_features()\n",
    "    for feature in data_feats.keys():\n",
    "        if feature not in features:\n",
    "            features.append(feature)\n",
    "\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2622957/2622957 [02:48<00:00, 15521.12it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "feature_matrix = np.zeros((len(training_data), len(features) + 2), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(len(training_data))):\n",
    "    data_point = training_data[i]\n",
    "    data_feats = data_point.to_features()\n",
    "    data_feat_vec = np.zeros(len(features))\n",
    "    for feature in data_feats.keys():\n",
    "        j = features.index(feature)\n",
    "        data_feat_vec[j] = 1\n",
    "    feature_matrix[i] = data_feat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622957, 4636)\n"
     ]
    }
   ],
   "source": [
    "print(feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = np.array(training_labels, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading instances...\n",
      "Loaded 334439 instances across 100000 exercises...\n",
      "Done loading 387374 instances across 115770 exercises.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 387374/387374 [00:46<00:00, 8260.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387374, 4636)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = load_data(\"en_es/en_es.slam.20190204.dev\")\n",
    "\n",
    "test_features = np.zeros((len(test_data), len(features)), dtype=np.uint8)\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    data_point = test_data[i]\n",
    "    data_feats = data_point.to_features()\n",
    "    data_feat_vec = np.zeros(len(features))\n",
    "    for feature in data_feats.keys():\n",
    "        if feature in features:\n",
    "            j = features.index(feature)\n",
    "            data_feat_vec[j] = 1\n",
    "    test_features[i] = data_feat_vec\n",
    "\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387374,)\n"
     ]
    }
   ],
   "source": [
    "test_labels = np.array(load_labels(\"en_es/en_es.slam.20190204.dev.key\"), dtype=np.uint8)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auroc(actual, predicted):\n",
    "    \"\"\"\n",
    "    Computes the area under the receiver-operator characteristic curve.\n",
    "    This code a rewriting of code by Ben Hamner, available here:\n",
    "    https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/auc.py\n",
    "    \"\"\"\n",
    "    num = len(actual)\n",
    "    temp = sorted([[predicted[i], actual[i]] for i in range(num)], reverse=True)\n",
    "\n",
    "    sorted_predicted = [row[0] for row in temp]\n",
    "    sorted_actual = [row[1] for row in temp]\n",
    "\n",
    "    sorted_posterior = sorted(zip(sorted_predicted, range(len(sorted_predicted))))\n",
    "    r = [0 for k in sorted_predicted]\n",
    "    cur_val = sorted_posterior[0][0]\n",
    "    last_rank = 0\n",
    "    for i in range(len(sorted_posterior)):\n",
    "        if cur_val != sorted_posterior[i][0]:\n",
    "            cur_val = sorted_posterior[i][0]\n",
    "            for j in range(last_rank, i):\n",
    "                r[sorted_posterior[j][1]] = float(last_rank+1+i)/2.0\n",
    "            last_rank = i\n",
    "        if i==len(sorted_posterior)-1:\n",
    "            for j in range(last_rank, i+1):\n",
    "                r[sorted_posterior[j][1]] = float(last_rank+i+2)/2.0\n",
    "\n",
    "    num_positive = len([0 for x in sorted_actual if x == 1])\n",
    "    num_negative = num - num_positive\n",
    "    sum_positive = sum([r[i] for i in range(len(r)) if sorted_actual[i] == 1])\n",
    "    auroc = ((sum_positive - num_positive * (num_positive + 1) / 2.0) / (num_negative * num_positive))\n",
    "\n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(actual, predicted):\n",
    "    \"\"\"\n",
    "    Computes the F1 score of your predictions. Note that we use 0.5 as the cutoff here.\n",
    "    \"\"\"\n",
    "    num = len(actual)\n",
    "\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        if actual[i] >= 0.5 and predicted[i] >= 0.5:\n",
    "            true_positives += 1\n",
    "        elif actual[i] < 0.5 and predicted[i] >= 0.5:\n",
    "            false_positives += 1\n",
    "        elif actual[i] >= 0.5 and predicted[i] < 0.5:\n",
    "            false_negatives += 1\n",
    "        else:\n",
    "            true_negatives += 1\n",
    "\n",
    "    try:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "        F1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        F1 = 0.0\n",
    "\n",
    "    return F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.005, n_estimators=3203, num_leaves=2400)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.005, n_estimators=3203, num_leaves=2400)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.005, n_estimators=3203, num_leaves=2400)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(num_leaves=2400, n_estimators=3203, learning_rate=0.005)\n",
    "lgbm.fit(feature_matrix, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ACCURACY\"\"\"\n",
    "\"\"\"\n",
    "train_score = lgbm.score(feature_matrix, training_labels)\n",
    "print(train_score)\n",
    "test_score = lgbm.score(test_features, test_labels)\n",
    "print(test_score)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6192198824895261\n",
      "F1 Score: 0.3714659751768586\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AUC & F1\"\"\"\n",
    "\n",
    "predictions = lgbm.predict(test_features)\n",
    "roc = compute_auroc(test_labels, predictions)\n",
    "f1 = compute_f1(test_labels, predictions)\n",
    "\n",
    "print(f\"AUC: {roc}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idls23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
