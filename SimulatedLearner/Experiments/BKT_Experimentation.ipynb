{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6p_-SNLnnMYr"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from collections import defaultdict, namedtuple\n",
        "from io import open\n",
        "import math\n",
        "import os\n",
        "from random import shuffle, uniform\n",
        "from datetime import datetime\n",
        "from future.utils import iterkeys, iteritems\n",
        "\n",
        "from future.builtins import range\n",
        "from future.utils import iteritems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "AwUHPpH4Jujn"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ-3B9c7J6O9",
        "outputId": "a46001ba-d24d-4358-89ee-a81b847ab8b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login(key=\"4a6e96eb645ce23f4ada4b7f5106dcbaed287c63\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "a71aff55374b447b8b3f8432551a0c95",
            "d8ebe4f9f86a432dafe474079d9add40",
            "d1ec1651d51c410c9a195a50d9455739",
            "fe72b139f7cf4764ae5ff9441a45e141",
            "5a77a1eaf1eb4bc3969b8de387821b1d",
            "1ba975d0c14b4a259f3ae67f44551578",
            "127c8e8cd4be49a381d844c8e246bb7a",
            "f633a02bd2194924be8f81dd3c268456"
          ]
        },
        "id": "j2EXwnJmJ8qR",
        "outputId": "53c39e2e-1e8e-4f9a-b3ee-57bb2d29d30f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:r86a552j) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a71aff55374b447b8b3f8432551a0c95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Batch Accuracy</td><td>▁▆▄▆▅▆▆▅▆▆▅▄▆▄█▆▆▆▇▅▆▆▅█▇▇▆▇▆▇▆█▇▆▅▆▇▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Batch Accuracy</td><td>85.0</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">BKT baseline 1</strong> at: <a href='https://wandb.ai/idl-s23/BaseLine%20Ablations/runs/r86a552j' target=\"_blank\">https://wandb.ai/idl-s23/BaseLine%20Ablations/runs/r86a552j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230330_001658-r86a552j/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:r86a552j). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230330_002045-n3ql8jgq</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/idl-s23/BaseLine%20Ablations/runs/n3ql8jgq' target=\"_blank\">BKT baseline 2</a></strong> to <a href='https://wandb.ai/idl-s23/BaseLine%20Ablations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/idl-s23/BaseLine%20Ablations' target=\"_blank\">https://wandb.ai/idl-s23/BaseLine%20Ablations</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/idl-s23/BaseLine%20Ablations/runs/n3ql8jgq' target=\"_blank\">https://wandb.ai/idl-s23/BaseLine%20Ablations/runs/n3ql8jgq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    name = \"BKT baseline 2\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
        "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"BaseLine Ablations\" ### Project should be created in your wandb account \n",
        "    #config = config ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtgFeEFeo31o"
      },
      "outputs": [],
      "source": [
        "# Sigma is the L2 prior variance, regularizing the baseline model. Smaller sigma means more regularization.\n",
        "_DEFAULT_SIGMA = 20.0\n",
        "\n",
        "# Eta is the learning rate/step size for SGD. Larger means larger step size.\n",
        "_DEFAULT_ETA = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqjYTB9TpD99"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_data(filename):\n",
        "    \"\"\"\n",
        "    This method loads and returns the data in filename. If the data is labelled training data, it returns labels too.\n",
        "\n",
        "    Parameters:\n",
        "        filename: the location of the training or test data you want to load.\n",
        "\n",
        "    Returns:\n",
        "        data: a list of InstanceData objects from that data type and track.\n",
        "        labels (optional): if you specified training data, a dict of instance_id:label pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    # 'data' stores a list of 'InstanceData's as values.\n",
        "    data = []\n",
        "\n",
        "    # If this is training data, then 'labels' is a dict that contains instance_ids as keys and labels as values.\n",
        "    training = False\n",
        "    if filename.find('train') != -1:\n",
        "        training = True\n",
        "\n",
        "    if training:\n",
        "        labels = dict()\n",
        "\n",
        "    num_exercises = 0\n",
        "    print('Loading instances...')\n",
        "    instance_properties = dict()\n",
        "\n",
        "    with open(filename, 'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
        "            if len(line) == 0:\n",
        "                num_exercises += 1\n",
        "                if num_exercises % 100000 == 0:\n",
        "                    print('Loaded ' + str(len(data)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
        "                instance_properties = dict()\n",
        "\n",
        "            # If the line starts with #, then we're beginning a new exercise\n",
        "            elif line[0] == '#':\n",
        "                if 'prompt' in line:\n",
        "                    instance_properties['prompt'] = line.split(':')[1]\n",
        "                else:\n",
        "                    list_of_exercise_parameters = line[2:].split()\n",
        "                    for exercise_parameter in list_of_exercise_parameters:\n",
        "                        [key, value] = exercise_parameter.split(':')\n",
        "                        if key == 'countries':\n",
        "                            value = value.split('|')\n",
        "                        elif key == 'days':\n",
        "                            value = float(value)\n",
        "                        elif key == 'time':\n",
        "                            if value == 'null':\n",
        "                                value = None\n",
        "                            else:\n",
        "                                assert '.' not in value\n",
        "                                value = int(value)\n",
        "                        instance_properties[key] = value\n",
        "\n",
        "            # Otherwise we're parsing a new Instance for the current exercise\n",
        "            else:\n",
        "                line = line.split()\n",
        "                if training:\n",
        "                    assert len(line) == 7\n",
        "                else:\n",
        "                    assert len(line) == 6\n",
        "                assert len(line[0]) == 12\n",
        "\n",
        "                instance_properties['instance_id'] = line[0]\n",
        "\n",
        "                instance_properties['token'] = line[1]\n",
        "                instance_properties['part_of_speech'] = line[2]\n",
        "\n",
        "                instance_properties['morphological_features'] = dict()\n",
        "                for l in line[3].split('|'):\n",
        "                    [key, value] = l.split('=')\n",
        "                    if key == 'Person':\n",
        "                        value = int(value)\n",
        "                    instance_properties['morphological_features'][key] = value\n",
        "\n",
        "                instance_properties['dependency_label'] = line[4]\n",
        "                instance_properties['dependency_edge_head'] = int(line[5])\n",
        "                if training:\n",
        "                    label = float(line[6])\n",
        "                    labels[instance_properties['instance_id']] = label\n",
        "                data.append(InstanceData(instance_properties=instance_properties))\n",
        "\n",
        "        print('Done loading ' + str(len(data)) + ' instances across ' + str(num_exercises) +\n",
        "              ' exercises.\\n')\n",
        "\n",
        "    if training:\n",
        "        return data, labels\n",
        "    else:\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmOg5XiUpPCR"
      },
      "outputs": [],
      "source": [
        "class InstanceData(object):\n",
        "    \"\"\"\n",
        "    A bare-bones class to store the included properties of each instance. This is meant to act as easy access to the\n",
        "    data, and provides a launching point for deriving your own features from the data.\n",
        "    \"\"\"\n",
        "    def __init__(self, instance_properties):\n",
        "\n",
        "        # Parameters specific to this instance\n",
        "        self.instance_id = instance_properties['instance_id']\n",
        "        self.token = instance_properties['token']\n",
        "        self.part_of_speech = instance_properties['part_of_speech']\n",
        "        self.morphological_features = instance_properties['morphological_features']\n",
        "        self.dependency_label = instance_properties['dependency_label']\n",
        "        self.dependency_edge_head = instance_properties['dependency_edge_head']\n",
        "\n",
        "        # Derived parameters specific to this instance\n",
        "        self.exercise_index = int(self.instance_id[8:10])\n",
        "        self.token_index = int(self.instance_id[10:12])\n",
        "\n",
        "        # Derived parameters specific to this exercise\n",
        "        self.exercise_id = self.instance_id[:10]\n",
        "\n",
        "        # Parameters shared across the whole session\n",
        "        self.user = instance_properties['user']\n",
        "        self.countries = instance_properties['countries']\n",
        "        self.days = instance_properties['days']\n",
        "        self.client = instance_properties['client']\n",
        "        self.session = instance_properties['session']\n",
        "        self.format = instance_properties['format']\n",
        "        self.time = instance_properties['time']\n",
        "        self.prompt = instance_properties.get('prompt', None)\n",
        "\n",
        "        # Derived parameters shared across the whole session\n",
        "        self.session_id = self.instance_id[:8]\n",
        "\n",
        "    def to_features(self):\n",
        "        \"\"\"\n",
        "        Prepares those features that we wish to use in the LogisticRegression example in this file. We introduce a bias,\n",
        "        and take a few included features to use. Note that this dict restructures the corresponding features of the\n",
        "        input dictionary, 'instance_properties'.\n",
        "\n",
        "        Returns:\n",
        "            to_return: a representation of the features we'll use for logistic regression in a dict. A key/feature is a\n",
        "                key/value pair of the original 'instance_properties' dict, and we encode this feature as 1.0 for 'hot'.\n",
        "        \"\"\"\n",
        "        to_return = dict()\n",
        "\n",
        "        to_return['bias'] = 1.0\n",
        "        to_return['user:' + self.user] = 1.0\n",
        "        to_return['format:' + self.format] = 1.0\n",
        "        to_return['token:' + self.token.lower()] = 1.0\n",
        "\n",
        "        to_return['part_of_speech:' + self.part_of_speech] = 1.0\n",
        "        for morphological_feature in self.morphological_features:\n",
        "            to_return['morphological_feature:' + morphological_feature] = 1.0\n",
        "        to_return['dependency_label:' + self.dependency_label] = 1.0\n",
        "        \n",
        "        time = datetime.now()\n",
        "        if(time.second %10 == 0 and time.microsecond == 0):\n",
        "          print(time)\n",
        "          \n",
        "        return to_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaY8GGIgqBGc"
      },
      "outputs": [],
      "source": [
        "class LogisticRegressionInstance(namedtuple('Instance', ['features', 'label', 'name'])):\n",
        "    \"\"\"\n",
        "    A named tuple for packaging together the instance features, label, and name.\n",
        "    \"\"\"\n",
        "    def __new__(cls, features, label, name):\n",
        "        if label:\n",
        "            if not isinstance(label, (int, float)):\n",
        "                raise TypeError('LogisticRegressionInstance label must be a number.')\n",
        "            label = float(label)\n",
        "        if not isinstance(features, dict):\n",
        "            raise TypeError('LogisticRegressionInstance features must be a dict.')\n",
        "        return super(LogisticRegressionInstance, cls).__new__(cls, features, label, name)\n",
        "\n",
        "\n",
        "class LogisticRegression(object):\n",
        "    \"\"\"\n",
        "    An L2-regularized logistic regression object trained using stochastic gradient descent.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sigma=_DEFAULT_SIGMA, eta=_DEFAULT_ETA):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.sigma = sigma  # L2 prior variance\n",
        "        self.eta = eta  # initial learning rate\n",
        "        self.weights = defaultdict(lambda: uniform(-1.0, 1.0)) # weights initialize to random numbers\n",
        "        self.fcounts = None # this forces smaller steps for things we've seen often before\n",
        "\n",
        "    def predict_instance(self, instance):\n",
        "        \"\"\"\n",
        "        This computes the logistic function of the dot product of the instance features and the weights.\n",
        "        We truncate predictions at ~10^(-7) and ~1 - 10^(-7).\n",
        "        \"\"\"\n",
        "        a = min(17., max(-17., sum([float(self.weights[k]) * instance.features[k] for k in instance.features])))\n",
        "        return 1. / (1. + math.exp(-a))\n",
        "\n",
        "    def error(self, instance):\n",
        "        return instance.label - self.predict_instance(instance)\n",
        "\n",
        "    def reset(self):\n",
        "        self.fcounts = defaultdict(int)\n",
        "\n",
        "    def training_update(self, instance):\n",
        "        if self.fcounts is None:\n",
        "            self.reset()\n",
        "        err = self.error(instance)\n",
        "        for k in instance.features:\n",
        "            rate = self.eta / math.sqrt(1 + self.fcounts[k])\n",
        "            # L2 regularization update\n",
        "            if k != 'bias':\n",
        "                self.weights[k] -= rate * self.weights[k] / self.sigma ** 2\n",
        "            # error update\n",
        "            self.weights[k] += rate * err * instance.features[k]\n",
        "            # increment feature count for learning rate\n",
        "            self.fcounts[k] += 1\n",
        "\n",
        "    def train(self, train_set, dev_set, iterations=10):\n",
        "        for it in range(iterations):\n",
        "            print('Training iteration ' + str(it+1) + '/' + str(iterations) + '...')\n",
        "            shuffle(train_set)\n",
        "            i = 0\n",
        "            for instance in train_set:\n",
        "                self.training_update(instance)\n",
        "                if(i % 100 == 0):\n",
        "                    print(str(i) + \" out of \" + str(len(train_set)))\n",
        "                    i +=1\n",
        "            predictions = self.predict_test_set(dev_set)\n",
        "            labels = load_labels(\"/content/en_es/en_es.slam.20190204.dev.key\")\n",
        "\n",
        "            directory = os.path.dirname(\"/content/out.pred\" + str(it))\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "            with open(\"/content/out.pred\" + str(it), 'wt') as f:\n",
        "              for instance_id, prediction in iteritems(predictions):\n",
        "                  f.write(instance_id + ' ' + str(prediction) + '\\n')\n",
        "                  \n",
        "            predictions = load_labels(\"/content/out.pred\" + str(it))\n",
        "\n",
        "            actual = []\n",
        "            predicted = []\n",
        "\n",
        "            for instance_id in iterkeys(labels):\n",
        "                try:\n",
        "                    actual.append(labels[instance_id])\n",
        "                    predicted.append(predictions[instance_id])\n",
        "                except KeyError:\n",
        "                    print('No prediction for instance ID ' + instance_id + '!')\n",
        "\n",
        "            acc, avg_log_loss, auroc, F1 = evaluate_metrics(actual, predicted)\n",
        "            print(\"acc : \" + str(acc) + \" avg log loss: \" + str(avg_log_loss) + \" auroc: \" + str(auroc) + \" F1: \" + str(F1))\n",
        "            print('Saving to WandB')\n",
        "            wandb.log({'Log Loss': avg_log_loss, 'aucroc': auroc, 'F1': F1,'accuracy': acc})\n",
        "\n",
        "        \n",
        "        print('\\n')\n",
        "\n",
        "    def predict_test_set(self, test_set):\n",
        "        return {instance.name: self.predict_instance(instance) for instance in test_set}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq_gnhSbK7UR"
      },
      "outputs": [],
      "source": [
        "def load_labels(filename):\n",
        "    \"\"\"\n",
        "    This loads labels, either the actual ones or your predictions.\n",
        "\n",
        "    Parameters:\n",
        "        filename: the filename pointing to your labels\n",
        "\n",
        "    Returns:\n",
        "        labels: a dict of instance_ids as keys and labels between 0 and 1 as values\n",
        "    \"\"\"\n",
        "    labels = dict()\n",
        "\n",
        "    with open(filename, 'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            else:\n",
        "                line = line.split()\n",
        "            instance_id = line[0]\n",
        "            label = float(line[1])\n",
        "            labels[instance_id] = label\n",
        "    return labels\n",
        "\n",
        "\n",
        "def compute_acc(actual, predicted):\n",
        "    \"\"\"\n",
        "    Computes the accuracy of your predictions, using 0.5 as a cutoff.\n",
        "\n",
        "    Note that these inputs are lists, not dicts; they assume that actual and predicted are in the same order.\n",
        "\n",
        "    Parameters (here and below):\n",
        "        actual: a list of the actual labels\n",
        "        predicted: a list of your predicted labels\n",
        "    \"\"\"\n",
        "    num = len(actual)\n",
        "    acc = 0.\n",
        "    for i in range(num):\n",
        "        if round(actual[i], 0) == round(predicted[i], 0):\n",
        "            acc += 1.\n",
        "    acc /= num\n",
        "    return acc\n",
        "\n",
        "\n",
        "def compute_avg_log_loss(actual, predicted):\n",
        "    \"\"\"\n",
        "    Computes the average log loss of your predictions.\n",
        "    \"\"\"\n",
        "    num = len(actual)\n",
        "    loss = 0.\n",
        "\n",
        "    for i in range(num):\n",
        "        p = predicted[i] if actual[i] > .5 else 1. - predicted[i]\n",
        "        loss -= math.log(p)\n",
        "    loss /= num\n",
        "    return loss\n",
        "\n",
        "\n",
        "def compute_auroc(actual, predicted):\n",
        "    \"\"\"\n",
        "    Computes the area under the receiver-operator characteristic curve.\n",
        "    This code a rewriting of code by Ben Hamner, available here:\n",
        "    https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/auc.py\n",
        "    \"\"\"\n",
        "    num = len(actual)\n",
        "    temp = sorted([[predicted[i], actual[i]] for i in range(num)], reverse=True)\n",
        "\n",
        "    sorted_predicted = [row[0] for row in temp]\n",
        "    sorted_actual = [row[1] for row in temp]\n",
        "\n",
        "    sorted_posterior = sorted(zip(sorted_predicted, range(len(sorted_predicted))))\n",
        "    r = [0 for k in sorted_predicted]\n",
        "    cur_val = sorted_posterior[0][0]\n",
        "    last_rank = 0\n",
        "    for i in range(len(sorted_posterior)):\n",
        "        if cur_val != sorted_posterior[i][0]:\n",
        "            cur_val = sorted_posterior[i][0]\n",
        "            for j in range(last_rank, i):\n",
        "                r[sorted_posterior[j][1]] = float(last_rank+1+i)/2.0\n",
        "            last_rank = i\n",
        "        if i==len(sorted_posterior)-1:\n",
        "            for j in range(last_rank, i+1):\n",
        "                r[sorted_posterior[j][1]] = float(last_rank+i+2)/2.0\n",
        "\n",
        "    num_positive = len([0 for x in sorted_actual if x == 1])\n",
        "    num_negative = num - num_positive\n",
        "    sum_positive = sum([r[i] for i in range(len(r)) if sorted_actual[i] == 1])\n",
        "    auroc = ((sum_positive - num_positive * (num_positive + 1) / 2.0) / (num_negative * num_positive))\n",
        "\n",
        "    return auroc\n",
        "\n",
        "\n",
        "def compute_f1(actual, predicted):\n",
        "    \"\"\"\n",
        "    Computes the F1 score of your predictions. Note that we use 0.5 as the cutoff here.\n",
        "    \"\"\"\n",
        "    num = len(actual)\n",
        "\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "    true_negatives = 0\n",
        "\n",
        "    for i in range(num):\n",
        "        if actual[i] >= 0.5 and predicted[i] >= 0.5:\n",
        "            true_positives += 1\n",
        "        elif actual[i] < 0.5 and predicted[i] >= 0.5:\n",
        "            false_positives += 1\n",
        "        elif actual[i] >= 0.5 and predicted[i] < 0.5:\n",
        "            false_negatives += 1\n",
        "        else:\n",
        "            true_negatives += 1\n",
        "\n",
        "    try:\n",
        "        precision = true_positives / (true_positives + false_positives)\n",
        "        recall = true_positives / (true_positives + false_negatives)\n",
        "        F1 = 2 * precision * recall / (precision + recall)\n",
        "    except ZeroDivisionError:\n",
        "        F1 = 0.0\n",
        "\n",
        "    return F1\n",
        "\n",
        "\n",
        "def evaluate_metrics(actual, predicted):\n",
        "    \"\"\"\n",
        "    This computes and returns a dictionary of notable evaluation metrics for your predicted labels.\n",
        "    \"\"\"\n",
        "    acc = compute_acc(actual, predicted)\n",
        "    avg_log_loss = compute_avg_log_loss(actual, predicted)\n",
        "    auroc = compute_auroc(actual, predicted)\n",
        "    F1 = compute_f1(actual, predicted)\n",
        "\n",
        "    return  acc, avg_log_loss,  auroc, F1\n",
        "\n",
        "\n",
        "def test_metrics():\n",
        "    actual = [1, 0, 0, 1, 1, 0, 0, 1, 0, 1]\n",
        "    predicted = [0.8, 0.2, 0.6, 0.3, 0.1, 0.2, 0.3, 0.9, 0.2, 0.7]\n",
        "    metrics = evaluate_metrics(actual, predicted)\n",
        "    metrics = {key: round(metrics[key], 3) for key in iterkeys(metrics)}\n",
        "    assert metrics['accuracy'] == 0.700\n",
        "    assert metrics['avglogloss'] == 0.613\n",
        "    assert metrics['auroc'] == 0.740\n",
        "    assert metrics['F1'] == 0.667\n",
        "    print('Verified that our environment is calculating metrics correctly.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IoOit8mo6ij",
        "outputId": "c94f0360-d0f5-4151-ff9d-61098d78c1e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading instances...\n",
            "Loaded 317049 instances across 100000 exercises...\n",
            "Loaded 635368 instances across 200000 exercises...\n",
            "Loaded 951536 instances across 300000 exercises...\n",
            "Loaded 1271940 instances across 400000 exercises...\n",
            "Loaded 1591344 instances across 500000 exercises...\n",
            "Loaded 1911212 instances across 600000 exercises...\n",
            "Loaded 2227444 instances across 700000 exercises...\n",
            "Loaded 2546704 instances across 800000 exercises...\n",
            "Done loading 2622957 instances across 824012 exercises.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data, training_labels = load_data(\"/content/en_es/en_es.slam.20190204.train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypaQjea31qqJ",
        "outputId": "a7870971-67a5-425f-d4c8-b9b23b3543c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading instances...\n",
            "Loaded 334439 instances across 100000 exercises...\n",
            "Done loading 387374 instances across 115770 exercises.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_data = load_data(\"/content/en_es/en_es.slam.20190204.dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI9qlKyVUZZ5",
        "outputId": "95582784-3c8b-45ea-b925-5771f3f7bcfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bias': 1.0,\n",
              " 'user:XEinXf5+': 1.0,\n",
              " 'format:reverse_translate': 1.0,\n",
              " 'token:i': 1.0,\n",
              " 'part_of_speech:PRON': 1.0,\n",
              " 'morphological_feature:Case': 1.0,\n",
              " 'morphological_feature:Number': 1.0,\n",
              " 'morphological_feature:Person': 1.0,\n",
              " 'morphological_feature:PronType': 1.0,\n",
              " 'morphological_feature:fPOS': 1.0,\n",
              " 'dependency_label:nsubj': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "training_data[0].to_features()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WytfgA_BTpAh"
      },
      "outputs": [],
      "source": [
        "exercices = {}\n",
        "word_dict = {}\n",
        "unique_word_index = 0;\n",
        "for instance in training_data:\n",
        "  user = instance.user\n",
        "  instance_id = instance.instance_id[:-2]\n",
        "  if user not in exercices:\n",
        "    exercices[user] = {}\n",
        "  if instance_id not in exercices[user] :\n",
        "    exercices[user][instance_id] = []\n",
        "  token = instance.token.lower()\n",
        "  if token in word_dict:\n",
        "    exercices[user][instance_id].append(word_dict[token])\n",
        "  else:\n",
        "    word_dict[token] = unique_word_index\n",
        "    exercices[user][instance_id].append(word_dict[token])\n",
        "    unique_word_index += 1\n",
        "\n",
        "exercices_merged = {}\n",
        "for user in exercices:\n",
        "  exercices_merged[user] = list(exercices[user].values())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(exercices_merged.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGJ8nu3CISxm",
        "outputId": "e110db3d-1671-41c4-e528-d17dfa4edfd5"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2593"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_exercices = {}\n",
        "for instance in test_data:\n",
        "  user = instance.user\n",
        "  instance_id = instance.instance_id[:-2]\n",
        "  if user not in test_exercices:\n",
        "    test_exercices[user] = {}\n",
        "  if instance_id not in test_exercices[user] :\n",
        "    test_exercices[user][instance_id] = []\n",
        "  token = instance.token.lower()\n",
        "  if token in word_dict:\n",
        "    test_exercices[user][instance_id].append(word_dict[token])\n",
        "  else:\n",
        "    test_exercices[user][instance_id].append(-1)\n",
        "\n",
        "test_exercices_merged = {}\n",
        "for user in test_exercices:\n",
        "  test_exercices_merged[user] = list(test_exercices[user].values())"
      ],
      "metadata": {
        "id": "hqwiPoG8_SXV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_exercices_merged[\"XEinXf5+\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4v-W3z-_2iZ",
        "outputId": "bab1d2d5-d8a5-40ca-dcb4-bdc4162386de"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[104, 320],\n",
              " [32, 28, 320],\n",
              " [651, 30, 717],\n",
              " [482, 327, 30, 322],\n",
              " [77, 110, 324],\n",
              " [325],\n",
              " [327, 322, 328, 30, 329],\n",
              " [847, 8, 2, 331, 336, 77, 106],\n",
              " [325, 8, 2, 331, 336, 77, 106],\n",
              " [77, 719],\n",
              " [77, 610, 8, 2, 697],\n",
              " [4, 330, 43, 333],\n",
              " [77, 334],\n",
              " [62, 339, 37],\n",
              " [28, 286],\n",
              " [28, 31],\n",
              " [77, 341],\n",
              " [279, 280, 30, 259],\n",
              " [10, 159],\n",
              " [0, 165, 166],\n",
              " [164, 115],\n",
              " [6, 306, 8, 28],\n",
              " [77, 303, 35, 304],\n",
              " [238, 8, 77, 343],\n",
              " [0, 83, 6, 344],\n",
              " [238, 8, 6, 345],\n",
              " [15, 8, 6, 485],\n",
              " [77, 591],\n",
              " [77, 487],\n",
              " [77, 501],\n",
              " [10, 8, 6, 500],\n",
              " [6, 58, 8, 2, 629],\n",
              " [10, 8, 2, 148],\n",
              " [12, 8, 349],\n",
              " [77, 350, 153],\n",
              " [56, 353],\n",
              " [35, 146, 359],\n",
              " [6, 113, 8, 358],\n",
              " [77, 112, 8, 70, 357],\n",
              " [77, 102],\n",
              " [77, 180],\n",
              " [0, 1, 56, 77, 291],\n",
              " [10, 8, 2, 833]]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1qpvvPUsf_l"
      },
      "outputs": [],
      "source": [
        "training_instances = [LogisticRegressionInstance(features=instance_data.to_features(),\n",
        "                                                  label=training_labels[instance_data.instance_id],\n",
        "                                                  name=instance_data.instance_id\n",
        "                                                  ) for instance_data in training_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_cuITNPspz6"
      },
      "outputs": [],
      "source": [
        "keys_data = {}\n",
        "for instance in training_instances:\n",
        "  keys = instance.features.keys()\n",
        "  for key in keys:\n",
        "    if key in keys_data:\n",
        "      keys_data[key] += instance.features[key]\n",
        "    else:\n",
        "      keys_data[key] = instance.features[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CH_oOuMsvSc"
      },
      "outputs": [],
      "source": [
        "test_instances = [LogisticRegressionInstance(features=instance_data.to_features(),\n",
        "                                                 label=None,\n",
        "                                                 name=instance_data.instance_id\n",
        "                                                 ) for instance_data in test_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdBnBXK_sxhs"
      },
      "outputs": [],
      "source": [
        "logistic_regression_model = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPiqaRNrsya_",
        "outputId": "3ae52312-444f-4a2a-a600-08b3ffbce19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training iteration 1/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8596937326717848 avg log loss: 0.3593452346640574 auroc: 0.7479930335504222 F1: 0.0963338598387231\n",
            "Saving to WandB\n",
            "Training iteration 2/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8605611114839922 avg log loss: 0.35349000906632144 auroc: 0.7607264505626681 F1: 0.1182232234683383\n",
            "Saving to WandB\n",
            "Training iteration 3/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8612297159850687 avg log loss: 0.35058050424851606 auroc: 0.7663706816152711 F1: 0.14218236364216638\n",
            "Saving to WandB\n",
            "Training iteration 4/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8614646310800416 avg log loss: 0.3491360286557647 auroc: 0.7694004226107698 F1: 0.14864757674307924\n",
            "Saving to WandB\n",
            "Training iteration 5/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8617563388353374 avg log loss: 0.34810966982513547 auroc: 0.7714736786751871 F1: 0.153970109640115\n",
            "Saving to WandB\n",
            "Training iteration 6/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8619060649398256 avg log loss: 0.347310578847728 auroc: 0.7728377371244854 F1: 0.1650694552832839\n",
            "Saving to WandB\n",
            "Training iteration 7/20...\n",
            "0 out of 2622957\n",
            "acc : 0.862097094797276 avg log loss: 0.346857251909001 auroc: 0.7737993884502532 F1: 0.16570357644853975\n",
            "Saving to WandB\n",
            "Training iteration 8/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8621358170656781 avg log loss: 0.3464086571928194 auroc: 0.7745873223730644 F1: 0.17182290455144608\n",
            "Saving to WandB\n",
            "Training iteration 9/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8621590504267194 avg log loss: 0.3461107332191568 auroc: 0.7751907360207712 F1: 0.1733597547759854\n",
            "Saving to WandB\n",
            "Training iteration 10/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8621280726119978 avg log loss: 0.34590714614741225 auroc: 0.7756376012771794 F1: 0.17381350163975\n",
            "Saving to WandB\n",
            "Training iteration 11/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8622907061392866 avg log loss: 0.345620817157958 auroc: 0.776004012954757 F1: 0.18291543492578918\n",
            "Saving to WandB\n",
            "Training iteration 12/20...\n",
            "0 out of 2622957\n",
            "acc : 0.862370732160651 avg log loss: 0.34544857861539197 auroc: 0.7763295042531949 F1: 0.18442710723573505\n",
            "Saving to WandB\n",
            "Training iteration 13/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8623758951297712 avg log loss: 0.34529935180569554 auroc: 0.776586539965117 F1: 0.1860763358778626\n",
            "Saving to WandB\n",
            "Training iteration 14/20...\n",
            "0 out of 2622957\n",
            "acc : 0.862424943336414 avg log loss: 0.3452058369285655 auroc: 0.7767878091153991 F1: 0.1860557464681176\n",
            "Saving to WandB\n",
            "Training iteration 15/20...\n",
            "0 out of 2622957\n",
            "acc : 0.862499806388658 avg log loss: 0.34509285682268115 auroc: 0.7769960551863528 F1: 0.18698293494520257\n",
            "Saving to WandB\n",
            "Training iteration 16/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8624378507592146 avg log loss: 0.34502090979627503 auroc: 0.7771708825069732 F1: 0.18703850613291026\n",
            "Saving to WandB\n",
            "Training iteration 17/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8624739915430566 avg log loss: 0.3449016247545122 auroc: 0.7773005276366635 F1: 0.19166691955208934\n",
            "Saving to WandB\n",
            "Training iteration 18/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8624688285739363 avg log loss: 0.3448358158614373 auroc: 0.7774563819485679 F1: 0.19114565936902195\n",
            "Saving to WandB\n",
            "Training iteration 19/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8625385286570602 avg log loss: 0.34477697834648074 auroc: 0.7775407361262786 F1: 0.1927688925945577\n",
            "Saving to WandB\n",
            "Training iteration 20/20...\n",
            "0 out of 2622957\n",
            "acc : 0.8625565990489811 avg log loss: 0.34472230773002543 auroc: 0.7776521502598559 F1: 0.1943771940443046\n",
            "Saving to WandB\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "logistic_regression_model.train(training_instances,test_instances, iterations=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEeJ9wZRsz7U"
      },
      "outputs": [],
      "source": [
        "predictions = logistic_regression_model.predict_test_set(test_instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kFix2fis1hr"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/out.pred\", 'wt') as f:\n",
        "    for instance_id, prediction in iteritems(predictions):\n",
        "        f.write(instance_id + ' ' + str(prediction) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fArgEH1ugwy",
        "outputId": "c45a0a45-ac67-4c86-cf9c-d994f340c478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading labels for exercises...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics:\taccuracy=0.862\tavglogloss=0.346\tauroc=0.776\tF1=0.180\n"
          ]
        }
      ],
      "source": [
        "print('\\nLoading labels for exercises...')\n",
        "labels = load_labels(\"/content/en_es/en_es.slam.20190204.dev.key\")\n",
        "print(labels)\n",
        "print('Loading predictions for exercises...')\n",
        "predictions = load_labels(\"/content/out.pred\")\n",
        "\n",
        "actual = []\n",
        "predicted = []\n",
        "\n",
        "for instance_id in iterkeys(labels):\n",
        "    try:\n",
        "        actual.append(labels[instance_id])\n",
        "        predicted.append(predictions[instance_id])\n",
        "    except KeyError:\n",
        "        print('No prediction for instance ID ' + instance_id + '!')\n",
        "\n",
        "metrics = evaluate_metrics(actual, predicted)\n",
        "line = '\\t'.join([('%s=%.3f' % (metric, value)) for (metric, value) in iteritems(metrics)])\n",
        "print('Metrics:\\t' + line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "764N7tWruxKf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIdndXnJZLr5"
      },
      "source": [
        "## Test BKT "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo8__70EZQQT"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "-Tp0Q3EBZOsD"
      },
      "outputs": [],
      "source": [
        "class BKTLearner(object):\n",
        "    \n",
        "    def __init__(self, state_size, slip_prob, transition_prob, guess_prob):\n",
        "        self.state_size = state_size\n",
        "        self.state = np.zeros(self.state_size)\n",
        "        self.slip_prob = slip_prob\n",
        "        self.transition_prob = transition_prob\n",
        "        self.guess_prob = guess_prob\n",
        "    \n",
        "    def reset(self):\n",
        "        self.state = np.zeros(self.state_size)\n",
        "        \n",
        "    def predictAnswer(self, input):\n",
        "        answer = []\n",
        "        for token_index in input:\n",
        "            p_correct = self.state[token_index] * (1 - self.slip_prob) + (1 - self.state[token_index]) * self.guess_prob \n",
        "            value = np.random.choice(np.array([0,1]), p = np.array([1 - p_correct, p_correct]))\n",
        "            answer.append(value)\n",
        "        return np.array(answer)\n",
        "    \n",
        "    def updateKnowledgeState(self, output_correctness, tokens):\n",
        "        i = 0\n",
        "        for token_index in tokens:\n",
        "            if output_correctness[i] == 1:\n",
        "                PLt_obs = self.state[token_index]*(1 - self.slip_prob) / (self.state[token_index]*(1 - self.slip_prob) + (1 - self.state[token_index])*self.guess_prob)\n",
        "            else:\n",
        "                PLt_obs = self.state[token_index]*(self.slip_prob) / (self.state[token_index]*(self.slip_prob) + (1 - self.state[token_index])*(1 - self.guess_prob))\n",
        "            #print(PLt_obs ,self.state[token_index],self.slip_prob,self.guess_prob, output_correctness[i], token_index)\n",
        "            self.state[token_index] = PLt_obs + (1 - PLt_obs)*self.transition_prob\n",
        "            i += 1 \n",
        "    \n",
        "    def trainOneSet(self, excercises):\n",
        "        for exercise in excercises:\n",
        "            answer_correctness = self.predictAnswer(exercise)\n",
        "            self.updateKnowledgeState(answer_correctness, exercise)\n",
        "    \n",
        "    def testOneSet(self, excercises):\n",
        "        answer_correctness = []\n",
        "        for exercise in excercises:\n",
        "            answer_correctness_ex = self.predictAnswer(exercise)\n",
        "            answer_correctness.append(answer_correctness_ex)\n",
        "        return np.array(answer_correctness)\n",
        "        \n",
        "    def computeAccuracyForTest(self, test_response):\n",
        "        correct = 0;\n",
        "        total = 0;\n",
        "        for exercise in test_response:\n",
        "            for token in exercise:\n",
        "                correct += token\n",
        "                total += 1\n",
        "        \n",
        "        if(total == 0):\n",
        "          return 0\n",
        "\n",
        "        return float(correct)/total * 100\n",
        "    \n",
        "    def train(self, exercices_all, train_duration, test_duration):\n",
        "        i = 0;\n",
        "        accuracy = 0\n",
        "        batch = 0\n",
        "        \n",
        "        while i < len(exercices_all):\n",
        "            train_batch = exercices_all[i:train_duration + i]\n",
        "            self.trainOneSet(train_batch)\n",
        "            i += train_duration\n",
        "            test_batch = exercices_all[i:i + test_duration]\n",
        "            answer_correctness = self.testOneSet(test_batch)\n",
        "            i += test_duration\n",
        "            accuracy = self.computeAccuracyForTest(answer_correctness) \n",
        "            print(\"Batch + \" + str(batch) + \" \" + \" correct: \" + str(accuracy))\n",
        "            wandb.log({'Batch Accuracy': accuracy})\n",
        "            batch += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "cHtp6W9BZSxH"
      },
      "outputs": [],
      "source": [
        "learner = BKTLearner(len(word_dict), 0.05, 0.1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(inv_word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShVNSMnBFNgV",
        "outputId": "ecfa566f-753d-4b48-a31a-79e66b3b93a4"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1967"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "6112ZZMngTU2"
      },
      "outputs": [],
      "source": [
        "inv_word_dict = {}\n",
        "for key, val in word_dict.items():\n",
        "  inv_word_dict[val] = key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dAI-V0Uxgda7",
        "outputId": "c6aab904-0685-4fbf-a878-2a4b171a93c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rather'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "inv_word_dict[684]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnzwDeotZdIv",
        "outputId": "98127cf9-8a9a-497a-8dc4-bda8dbbfb7cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch + 0  correct: 0\n",
            "Batch + 1  correct: 0\n",
            "Batch + 2  correct: 0\n",
            "Batch + 3  correct: 0\n",
            "Batch + 4  correct: 0\n",
            "Batch + 5  correct: 0\n",
            "Batch + 6  correct: 0\n",
            "Batch + 7  correct: 0\n",
            "Batch + 8  correct: 0\n",
            "Batch + 9  correct: 0\n",
            "Batch + 10  correct: 0\n",
            "Batch + 11  correct: 0\n",
            "Batch + 12  correct: 0\n",
            "Batch + 13  correct: 0\n",
            "Batch + 14  correct: 0\n",
            "Batch + 15  correct: 0\n",
            "Batch + 16  correct: 0\n",
            "Batch + 17  correct: 0\n",
            "Batch + 18  correct: 0\n",
            "Batch + 19  correct: 0\n",
            "Batch + 20  correct: 0\n",
            "Batch + 21  correct: 0\n",
            "Batch + 22  correct: 0\n",
            "Batch + 23  correct: 0\n",
            "Batch + 24  correct: 0\n",
            "Batch + 25  correct: 0\n",
            "Batch + 26  correct: 0\n",
            "Batch + 27  correct: 0\n",
            "Batch + 28  correct: 0\n",
            "Batch + 29  correct: 0\n",
            "Batch + 30  correct: 0\n",
            "Batch + 31  correct: 0\n",
            "Batch + 32  correct: 0\n",
            "Batch + 33  correct: 0\n",
            "Batch + 34  correct: 0\n",
            "Batch + 35  correct: 0\n"
          ]
        }
      ],
      "source": [
        "learner.train(exercices_merged[\"XEinXf5+\"], 10, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_exercices[\"XEinXf5+\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GVfQdeDA5b9",
        "outputId": "e68a0e91-d1d6-432a-b4f1-464f850f3f39"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rsAkJBG001': [104, 320],\n",
              " 'rsAkJBG002': [32, 28, 320],\n",
              " 'rsAkJBG003': [651, 30, 717],\n",
              " 'xR1LbGwW01': [482, 327, 30, 322],\n",
              " 'xR1LbGwW02': [77, 110, 324],\n",
              " 'ITvkpyv+01': [325],\n",
              " 'ITvkpyv+02': [327, 322, 328, 30, 329],\n",
              " 'ITvkpyv+03': [847, 8, 2, 331, 336, 77, 106],\n",
              " 'ITvkpyv+04': [325, 8, 2, 331, 336, 77, 106],\n",
              " '6wunbdfa01': [77, 719],\n",
              " '6wunbdfa02': [77, 610, 8, 2, 697],\n",
              " '6wunbdfa03': [4, 330, 43, 333],\n",
              " 'OM/eqPd701': [77, 334],\n",
              " 'OM/eqPd702': [62, 339, 37],\n",
              " 'ZjRIRR9s01': [28, 286],\n",
              " 'ZjRIRR9s02': [28, 31],\n",
              " 'ZjRIRR9s03': [77, 341],\n",
              " 'T4rpAznq01': [279, 280, 30, 259],\n",
              " 'djFqFxWS01': [10, 159],\n",
              " 'djFqFxWS02': [0, 165, 166],\n",
              " 'djFqFxWS03': [164, 115],\n",
              " '7KfZc1xB01': [6, 306, 8, 28],\n",
              " '7KfZc1xB02': [77, 303, 35, 304],\n",
              " 'BNZ3C6fs01': [238, 8, 77, 343],\n",
              " 'BNZ3C6fs02': [0, 83, 6, 344],\n",
              " '4C0NvZIf01': [238, 8, 6, 345],\n",
              " '4C0NvZIf02': [15, 8, 6, 485],\n",
              " 'Xywa9rJq01': [77, 591],\n",
              " 'Xywa9rJq02': [77, 487],\n",
              " 'Xywa9rJq03': [77, 501],\n",
              " 'obIZU+GP01': [10, 8, 6, 500],\n",
              " 'obIZU+GP02': [6, 58, 8, 2, 629],\n",
              " 'obIZU+GP03': [10, 8, 2, 148],\n",
              " '6nuqPwPa01': [12, 8, 349],\n",
              " '6nuqPwPa02': [77, 350, 153],\n",
              " '6nuqPwPa03': [56, 353],\n",
              " 'aaegLRB501': [35, 146, 359],\n",
              " 'aaegLRB502': [6, 113, 8, 358],\n",
              " 'aaegLRB503': [77, 112, 8, 70, 357],\n",
              " '6PHaTpy401': [77, 102],\n",
              " '6PHaTpy402': [77, 180],\n",
              " '6PHaTpy403': [0, 1, 56, 77, 291],\n",
              " '6PHaTpy404': [10, 8, 2, 833]}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Z6tYc6nRZtPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8389c917-348b-4782-d872-b7fd8ac4f472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-65-490f3330d96c>:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(answer_correctness)\n"
          ]
        }
      ],
      "source": [
        "res = learner.testOneSet(test_exercices_merged[\"XEinXf5+\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.logical_not(np.concatenate(res)).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S64jI63oAS9L",
        "outputId": "53e91c45-d150-43a9-a4ed-ccec127181fb"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array([1, 1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1])"
      ],
      "metadata": {
        "id": "Tmz1pkafBRB_"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhFNcD0sOr7e",
        "outputId": "5c6fc79c-46cf-4086-c42e-fce4a23c98c7"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_f1(labels,np.logical_not(np.concatenate(res)).astype(int))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h_J4uqrOxZS",
        "outputId": "8b4c5096-9dd5-4d33-d18a-c5068f9b9acf"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39080459770114945"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kTLqtG5SO6i0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "127c8e8cd4be49a381d844c8e246bb7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba975d0c14b4a259f3ae67f44551578": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a77a1eaf1eb4bc3969b8de387821b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71aff55374b447b8b3f8432551a0c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8ebe4f9f86a432dafe474079d9add40",
              "IPY_MODEL_d1ec1651d51c410c9a195a50d9455739"
            ],
            "layout": "IPY_MODEL_fe72b139f7cf4764ae5ff9441a45e141"
          }
        },
        "d1ec1651d51c410c9a195a50d9455739": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_127c8e8cd4be49a381d844c8e246bb7a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f633a02bd2194924be8f81dd3c268456",
            "value": 1
          }
        },
        "d8ebe4f9f86a432dafe474079d9add40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a77a1eaf1eb4bc3969b8de387821b1d",
            "placeholder": "​",
            "style": "IPY_MODEL_1ba975d0c14b4a259f3ae67f44551578",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "f633a02bd2194924be8f81dd3c268456": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe72b139f7cf4764ae5ff9441a45e141": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}